[Chapter break – "And This Is What Your Life Would Be Like If…" Times 200]

At this point, my story skips forward a bit.

You see, <em>I</em> wasn't the Marvin who had to build the initial duplication device. For <em>that</em> Marvin – who we later came to call Marvin Alpha – there were weeks of grueling work, [programming, building, keeping tabs on our prisoners and collaborators]. But for me, [I experienced only a few minutes of time from when we reset the original time machine to when Marvin Alpha and Kayla Alpha stepped out of it, to invite us into the future as their duplicates.]

As best I understand it, [Marvin Alpha had a terrible time/as soon as the adrenaline ran out, he had a mental breakdown/he couldn't concentrate on the engineering and locked himself in a room hiding for subjective days/Kayla Alpha had to yell at him to get back to work/he had a huge fight with Kayla where they both said hurtful things to each other, which he later deleted the recording of because he didn't want the rest of Marvins to be tempted to listen to it.] By the time he picked me up, he was barely holding it together. And he never wanted to be duplicated himself. We only duplicated the Marvins who started out like me, [not having had the crash yet, so that it could be made easier for them].

[Maybe here, or earlier, or later, the money thing:]

Fortunately, we had lots of money.

When you think about how to use time travel to make yourself rich, maybe the first thing you think of is guessing the winning lottery numbers. But Dr. Fuller hadn't done that, because he understood reputation management. He didn't want his name in the news as "the big lottery winner", to be followed around by scammers and charities, and distained by the genuinely wealthy. He wanted his every act to appear magnanimous rather than stingy – so he wanted complete control over how much of his infinite money to reveal, and when.

So maybe the next thing you'd think of is playing the stock market. Each day, you check which stock price has increased the most; then you go back to the previous day, and buy as much of that stock as you can; then you wait one day again, and then sell it. Naïvely, in a couple of months, you could grow $1 into $1 billion. But if you did this, you would be noticed by people much more dangerous than the scammers and the charities. Hedge funds and government regulators would be very interested to know how you'd achieved it. Before long, everyone in the finance world would know you as the "miracle investor", and the instant you tried to buy anything, everyone else would start buying it as well, driving up the price before you could buy much of it for the original, cheaper price. Your profits would disappear; you'd make the market incredibly volatile; there'd be paradoxes all over the place.

If you wanted to go unnoticed, you needed a different environment. An environment where you didn't have to trade under your real name, where the regulators wouldn't move fast enough to stop you – and where, when you tried to spend the millions of dollars you had pulled out of thin air, people wouldn't look too closely.

You needed cryptocurrency.

Dr. Fuller hadn't understood cryptocurrency himself – if he had, maybe he would have cheated at Bitcoin <em>mining</em>, instead of just trading. But the programmer he hired to hide his transactions, did understand it. At the time I took over, Dr. Fuller had nearly 100,000 anonymous accounts, across dozens of different cryptocurrencies. Each account had only done a few trades, for no more than $200,000 at a time – but in total, he was dealing in billions. Luckily for Dr. Fuller, the programmer was competent; even luckier, the programmer was only diverting around 10% of the ill-gotten profits into his own accounts, rather than stealing all of it at once.

But anonymous accounts are double-edged sword. If the account said "this is Jason Fuller's money", and then Marvin Fitzroy tried to spend it, maybe it wouldn't work; maybe there'd be some kind of fraud detection. But when the account says "this money belongs to whoever knows the secret password", and Marvin Fitzroy knows the secret password, who's to say it's not Marvin Fitzroy's money?


[Detailed narration of the initial duplication, with the "Kaylas arguing, Marvins hesitating" "this is painful to watch!" Thing]

And then my story skips forward <em>again</em>.

[You see, in the <em>first</em> timeline, the little group of us went on to start working together, establishing a little community and starting work on less janky time machines. And before long, they went back to duplicate another copy of the little group, so from the perspective of the second batch, right after they experienced being duplicated by Marvin Alpha, they experienced the little group of them being duplicated again, by the members of the first copy of the little group. But I wasn't in the second batch, either. Or the third, or the fourth. By the time they collected the batch that included <em>me</em>, there were already about 200 each of us. A community with policies. The Marvin and Kayla who picked me up looked much more [not haggard], and they had a much more professional-looking time machine]



[Being led past the bunch of Marvins who are hanging out, cuddling and playing video games]


He actually called it "onboarding", as if we were a tech company, and not [basically the SCP foundation].



[Onboarding: new Marvins are required to rest for at least a week, they can start getting to up to speed but can't work; each Marvin gets a new name/designation, chosen from a list of not-yet-used options; at some point the debriefer offers a hug, with discussion (dialog or narration? Maybe narration?) About how they experimented with the most effective way to get new Marvins comfortable with it]

["We originally tried to ease new Marvin's into this, but experimentation determines that it's best to dump it all on you at once. We have ADHD; here is your medication. We used to give new Marvin's time to ease into the idea of taking it, but please start taking it immediately, the relief of our ongoing undiagnosed issues makes the recovery from the immediate trauma much easier to handle"; the drug is Desoxyn, "it's literally methamphetamine. But we've tried a bunch of different medications and this was the most effective with the least side effects; we've already figured out the best dosage; it was difficult getting prescriptions because every time we had to be seeing that psychiatrists for the first time and of course because of the time travel, there was no record of how long we'd been taking it the previous medications, but we managed it [maybe don't specify how they managed it]"]

[Here's your approved fidget toy. It works for us and it's quiet. I know you like clicky fidgets, but it turns out we can't stand the noise when we're not the ones making it.]

[Probably mostly narration rather than dialogue: Here's your time travelling personal alarm. Here's a practice version, see it's labeled "practice" in orange writing, because it's impossible to get used to it without practice because you never remember pulling it. It has a camera in it, and when you pull the real one, it sends the last X minutes of recordings back in time by Y minutes and broadcasts an alert. If you ever see a Nochli in person, you need to pull it immediately, to make sure the Nochli doesn't see you first. It's also supposed to go off automatically if you die, although we haven't been able to test that one. Kayla volunteered but the ethics board said no. [It takes a bunch of force to pull] yeah we don't want it to go off by accident. We made them just the right amount of force so that Kayla can pull one using her full strength.



[When PoV-Marvin is being debriefed: "and we've only had a few time travel mishaps". I'm sure for [the debriefer] this felt like something to be proud of, because they had been programming for umpteen person-months, and only had a few mishaps. But for me, who had just recently [ranted about unit testing, thought about how I would do stuff reliably], it was like all my planning had immediately been rewarded by "haha, you failed anyway!". "A few mishaps?" I exploded. "????? [Every single mishap could immediately end the world as we know it]]




[debriefer warning Marvin about what could happen with Kaylas ("don't try to stop her from deleting herself"); video of "kayla going to delete herself". "The others all know what they're doing but I've [gotten dislodged out of it] – I was with 4 others who had [gotten dislodged] and they got back on track but I didn't – There's plenty more of me, and they're better… my existence has neither intrinsic value (because I don't enjoy it) nor instrumental value (because the others are a better use of resources than I am), so why shouldn't I delete myself??" "What is the point, we might as well just walk up to Nochli"... You should get therapy, we've been doing it and it's helpful. No way, not worth it, therapists will just tell me to be less of who I am. Well I'm not going to give up, even if you delete yourself today I'm going to keep trying to convince you to get therapy so you don't have to in the future, is that okay with you? Of course it's okay, [the only scenario where would I agree to it is one where I actually concluded it was a good idea, so asking is never a violation]]

[We call it "Kayla Management". Don't worry, Kayla knows that we call it that, she actually approves of it. She said it was a form of 'instrumentality' –]

"Instrumentality?"

"Apparently, that's something from feminist philosophy. It's [a form of objectification where you treat someone else as a tool to achieve your goals, literally an 'instrument'. And I thought she was criticizing me at first, but she was actually approving of it. She is instrumentalizing herself, she wants both of us to use her as efficiently as possible]



[You could technically try eating meat now because we're duplicating it, so it doesn't increase the amount of animals being mistreated? I mean, if you still think it's wrong, I respect your beliefs –/stop it! What if my beliefs are wrong, then you'd be respecting something that's wrong! You have to form your own opinion. "But what if I disagree with you?" "Then you'll be wrong"]




[in chapter: 93% Chance for a Software Bug to Destroy Civilization]


"We want to recruit an expert on Formal Verification."

[Marvin [not me] was presenting to the Ethics Board. This Marvin had an air of knowing what he was talking about – he was good at making professional presentations – he must have practiced a lot, because I wasn't that good at this]

?????

[Why should we approve this]

"[To prevent a mishap that would alert Nochli to our activities]"

[Reginald: "yes, of course it's [to defeat Nochli], that's the justification for EVERY request. You have to justify why [it is worth the risk of alerting Nochli that comes with every outing], and why there isn't a safer alternative that can accomplish the same goal."

[Marvin had a presentation for this]

["Based on our expected rate of software development that we will need, for plans that have already been agreed upon, we project [pointing at graphs] that the total amount of lines of code written will be 400000, resulting in 400 bugs and 80 additional time travel mishaps. With an estimated 3% chance of alerting Nochli for each time travel mishap… If we don't make drastic improvements to our programming practices… the projected probability of humanity's defeat due to software bugs is… 92%."]

[chapter break?]

[Having a powerful statistic like that does wonders to make a presentation more convincing. In business, people are always asking for money, and usually it's a hard sell, where even if you know that something is a good idea, it's hard to prove it to the stakeholders. But "92% chance of ending the world as we know it" did not leave much room for doubt. Everyone at the table was stunned. "Well," said Reginald, obviously struggling to maintain the polite decorum. The atmosphere in the room had clearly switched from "Marvin needs to convince Reginald" to "Reginald has a problem and is helping Marvin will have a solution". Reginald started asking about formal verification]

[it's where you mathematically prove that your code is correct. With unit tests, you can guarantee that the code behaves correctly in the situations that you thought of testing. But when the code goes into production, there's always going to be situations that you didn't think of. With mathematical proofs, you can guarantee that]

[Isn't that too good to be true? Why doesn't everyone do this?]

[Because it's difficult, takes a long time, and only a few people know how to do it. We've been following industry best practices for testing, like they use that big tech companies like Google and Microsoft – situations where a software bug usually won't kill hundreds of people. But it's sometimes used for safety critical systems like in avionics. Our systems are vastly more safety-critical than anything that has ever been built.]

[Why can't Marvins do this?]

[Some of us tried learning, and hired tutors as usual. But frankly, we aren't mathematicians. Next to regular programming, formal verification is like learning a whole new language. Kaylas might be able to do it, because she learns faster AND maintains a higher time ratio, but she's starting from 0 programming knowledge – getting a Kayla that point would take weeks of global time; we've estimated that getting a Kayla to equal Marvins' level of programming skill would take around 6 subjective years, and, there are, ah –" he glanced at the Kayla who was sitting on the ethics board]

"– unresolved challenges with extending a Kayla beyond 5 subjective years," said Kayla crisply. She looked like she was [about 21, and thus, near the end]. No doubt, she wanted to [nip this topic in the bud] [so as not to have it be the topic of debate] "We are working on improvements to Kayla Management. But there are no guarantees."

[We're talking about having this mathematician actually understand all of the time travel rules. For every additional person we bring in, we need to consider the risk that they will later make their own time machines. And turn Earth into Salnthu. How are you going to make sure that doesn't happen? Are you planning to lock them up for the rest of their life?]

[I joked that plenty of mathematicians would be happy to be locked up doing mathematics for the rest of their life]

["[It is not appropriate] for you to joke about [abuse] when you are in a position [where you could actually commit it]!"]

[Kayla talks about vetting them (see below)]

[There was some more debate, but the overwhelming necessity may be outcome inevitable – the ethics board unanimously approved the proposal. This really was something that couldn't be hired out without revealing what it was for, because defining the properties you needed to prove required you to understand the system]


[in chapter: Slightly Informed Consent]

Kayla: we can just use mind control to learn whether they are going to betray us or not

Reginald: you can't just go around mind controlling people, that's unethical

Kayla: we need background checks about anyone we're going to induct

Reginald: that doesn't mean you need mind control, you can use traditional methods. Once people develop the infrastructure for using a power, they never put it back in the box; are you prepared for a world where do you use mind control every time you want information out of people?

Kayla: okay, but if we do traditional detective work, we are going to be developing infrastructure for that as well, for using time machines to obtain private information about people. The result is the same, so how is that any less invasive?

Reginald: indeed, the result of obtaining private information without people's consent is invasive, regardless of how it's achieved. That's not something you can just do every time it seems helpful

Kayla: then how are we supposed to induct someone safely?

Reginald: No. You do not ask ME that question. You are the one who is proposing a compromise of ethics; you need to take responsibility for how to deal with it

Marvin: hang on, what if we CAN get their consent?

All: Huh?

Marvin: do an alternate future where you ask them if you can do invasive background checks; if they say yes, go back in time and do the checks; if they say no, go back in time and do nothing.

Somebody: uhhhh hang on, is that actually consent? If the person who's getting investigated doesn't remember giving permission?

Reginald: yeah, that's not a good consent system; an important part of consent systems is the ability of the subjects to trust the system. You would be the only ones with secret knowledge that the person actually gave permission, so even if you're not technically committing violations, no one else should trust that you aren't committing them; they should work to stop you, because if they don't, anyone could claim to have received permission for anything.

Marvin: wait wait wait, that's a solvable problem. When they give permission, we can record it; anytime the subject or a watchdog challenges us, we can reveal the recording. And of course, we'll get a record of ethics board approval for each individual act; and there can be a network of historical records preventing us from making excessive attempts to get the ethics board to authorize the same act in different timelines.

Reginald: see, now you're thinking how you need to be; designing HOW to earn people's trust, instead of just justifying what you wanted to do.

Someone: wait a minute, we can't actually show them the record, because they can't believe that time travel exists! we can't even get informed consent!

All: Uhhhhh

[Maybe: chapter break to the next chapter, "We, Uh, Work For A Secret Organization, Studying Aliens", which reveals their conclusions in medias res]





"I would have thought fighting aliens would [be like action/suspense movie stuff], not just having a mental breakdown in an office"


