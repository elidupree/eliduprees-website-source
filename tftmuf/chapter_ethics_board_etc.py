????? We owe it to Aster to let them use the antidote

[reg being different than Aster - deeper, gravelly voice, look of fear - in all the time we'd known Aster, we'd never seen them afraid, not even when the gun was being pointed at them. but Reginald was deeply afraid]

"I'm dissociating, you need to take me back to my office –"

"I'm sorry. We can't let you leave until we've explained what's going on"

?????

[At some point later: "what in God's name has Aster done with our back?? After all the work I did to try to learn good posture"]

[Reginald feeling utterly betrayed by Aster; as a grave whisper, "God damn it, Aster, what have you done?"]

["For the sixty years since the Monster Study and the Nuremberg Code, the field of neuroscience has been trying to earn back some semblance of not being morally bankrupt, and this has set that back enormously"]

[K+M offer excuses for Aster and Reginald argues against them
– "they were planning to get rid of Fuller" "
– "they thought Fuller might kill them" "well isn't that convenient for them! A convenient excuse to go on and do exactly what they would have wanted to get away with anyway! They should have risked our life"
– "They could have walked away" "if they'd walked away then I'd be dead because they didn't do time travel" "the fact that they could undo the deaths is why Fuller felt comfortable escalating the experiments in the first place! This is why you [bangs fist on table] never compromise with evil!"
– At some point, "'Reggie' is only a name for my intimates, I can't believe Aster gave it out to everyone"]

[With deeply aggrieved conviction] "If I get any say in this at all, we are going to have some god damn <em>ethics</em> around here."

[Chapter break, "the ethics board"]


[Reginald saying how everything up to this point has been an utter mess ethics wise, including some harsh words for Marvin's choices ("profoundly amoral act"/I hung my head/"at least you have the decency to be ashamed") and saying Kayla was "excused but not justified" (there is a difference between a justification and an excuse! We can excuse Kayla's [brutal murder of a man who had already surrendered] because [of her natural, extreme feelings about the situation he had put her in], but I will not sit here and allow you to justify it. More specifics, not sure of relative order:]

"[Marvin spied on innocent people.] Some of whom were children, I might add –"

[Need to fit in around here: discussion of Marvin delaying several days before doing anything about it even once he knew about the children,. "I was going to report it," I said, but I knew I wasn't sure if I really would have.]

[Kayla defensive of Marvin's spying because it led to her rescue]

"Did he know that?" Reginald demanded. ????? "[Did he know they were evil when he started]"

[Kayla defensive some more – "of course he knew they were evil! They put surveillance cameras all over the place, they turned this building into the goddamn Panopticon! Even if they hadn't [done nonconsensual experiments] they would still be evil –"]

But I knew that Reginald was right. [I hadn't thought about it at all – I was just lucky] I hung my head.

"At least you have the decency to be ashamed," said Reginald brusquely.



["Panopticon" – discussion of that and the company name, explanation of what it is: Kayla: "Jeremy Bentham described such a prison, claiming it would be good because it would stop the prisoners from doing bad stuff. But it would only make the prisoners do what the guard wants, and the guard would obviously be evil." Marvin: "how do we know the guard is evil?" [Maybe "anyone who wants to control people is evil" but hang on, what would Kayla actually think about an incorruptible good being watching people? "Also I thought even normal people know prison guards aren't paragons of virtue! Don't you know the Stanford prison experiment?"]]

Reginald: "I do not wish to defend surveillance, but as an educator, I must point out that the Stanford prison experiment has been discredited. [Details from the Thibault Le Texier paper]"

[About the company name, these surveillance companies aren't very creative and]




"Are you vegan?" Kayla cut in.

"I happen to enjoy a good steak on occasion," said Reginald [physicality: "Reginald sniffed", haughty-ish, sarcastic excuse-me tone].

Kayla [settled a little, not trying to press the issue but not feeling like Reginald's judgment was as much of a threat]

Reginald [understood the implication; implicitly, he recognized it as a threat to him being taken seriously]. "Are you going to [say I'm evil because I'm not vegan?]" [With a incredulous tone – a couple degrees less severe than "voice dripping with skepticism"]

Kayla shrugged. "Your lifestyle requires the murder of sapient beings," she said. Her tone wasn't accusatory – it was the tone of someone who is discussing the plain facts. "[You have no more right to judge than any of us]"

Reginald [got back on top of things]. "Even if I take that to be true, it only illustrates my point. If none of us are morally pure, then that is why we cannot simply defer to any one person's judgment, but must actively [work together to be rigorously protected against our individual flaws]"


[We need to get more, responsible, people, to have a proper ethics board. Wait a minute, we can't ethically bring in anyone because they can't give informed consent!]





If you were involved with the University of all, it was hard not to know about Dr. Ethel Wright.

One of the University's most respected and prolific physicists, she had authored and co-authored hundreds of papers in her long career. She was one of those people who simply never stops: Even in her old age, she was constantly moving on to the next project, the next ?????. She was old enough to have been the first woman on the physics faculty, and then later, the first woman head-of-department, a position she still held thirty years later.

I sat down with her in her office [physical description; she had arrived several hours before the 4 PM meeting, so we had time; she didn't know I was there to judge her]

"I'm a writer," I lied blandly. [I told her that Dr. Fuller had hired me, to prepare to have a favorable story to release to the public if we ever ended up in the public eye, and so now I was going around and talking to all of the scientists to have good background material]. "Don't worry, I'm 'in the know'," I said with a little wink [Probably not suave at all].

[She was a little surprised, but not unfavorable to the idea. I started with easy questions, learning a long story of interesting details about her history with the University]

[Pretty soon after she started talking] It was easy to see why Ethel Wright was so [widely respected]. [The way she spun the story immediately drew me in, and even her explanations of physics stuff were surprisingly understandable to me, a person who had bounced off physics in high school.]

?????

[An experiment involving an iron vessel, but the results were very confusing, and she kept forgetting to follow up on it]

"At that time I had a great deal of worry, as you can imagine, that age was catching up with me. [I have always defined my personal value based on the abilities of my mind, so losing that is like losing myself]. [But I thought about it in an analytical way, and it was conspicuous that the problem only appeared on this specific project – for reasons I'm sure you are aware of]"

?????

[Somehow I kept coming back to it, and even wrote the paper. But I didn't understand what was happening until a chance conversation with Re– ahem, with Dr. Nenge." I had the distinct impression that she was using his surname to show respect, since I was a stranger, but that she would normally call him Reggie, out of affection. Him? Them? She had probably been talking to Aster, actually[, they just hadn't come out to her]. "?????

"[He brought me to Dr. Fuller and they did some tests, showing me a series of chemical formulas and asking me to explain them, to show that my mind was normally functioning, and then showing me another one that I couldn't understand] It was very confusing to me at the time, but now I understand that they were showing me the formula for the argonization of iron. Dr. Nenge had derived it from our paper. Dr. Fuller could read it normally, because to him, the formula was laughable, a chemical impossibility. But for me, I would have understood it, because I had seen the results of our experiments. So it triggered the self-censoring effect.

?????

And then I came to the [big question that was the biggest purpose of this talk]. Keeping my voice casual, I continued, "how do you feel about the children?"

[Instantly icy] "Dr. Fuller didn't send you," she said [crisply? no, feeling-threatened-ly? no, more restrained than either].

?????

[She tries to call Doctor Fuller, the phone rings and rings – or is Marvin carrying the phone right now?] "

["Who are you and what have you done with Dr. Fuller?!"

"You called him," I said, momentarily stunned. I don't know what I had expected her to do once she [knew I was lying. Trying to protect him should certainly have been among the possibilities]. Maybe I just wasn't prepared for the reality that [someone who seemed respectable would actually take his side, knowing what he was really like] [kind of: stunned by the reality.] I shouldn't have been shocked by it, but seeing her actually do it – take Fuller's side the instant she knew there was a conflict – ?????

[She stood up from her desk]

"I wouldn't walk out that door if I were you," I said [dangerously] [Marvin didn't expect to be angry, but seeing that Dr. Wright knew about the children and tried to cover it up makes him start saying things in a somewhat angry way]

[Still dignified] "Are you threatening me?"

[My plans for how to talk to her were going off the rails, I was angry] "Dr. Fuller is dead," I declared. "We control the time machines now. ?????"

[She froze standing halfway to the door – I could see on her face that she was rebalancing how to approach this conversation] "I had nothing to do with Dr. Fuller's experiments –"

"You knew about them, and you tried to cover them up, [I accused]. "Do you know what Reggie did when we first met him? The instant he knew we were enemies of Fuller, he was on our side and against Fuller, he told us everything. But <em>you</em> – you tried to cover for him, you tried to warn him about me –"

"Dr. Fuller [has authority – had authority – over this entire project, he would retaliate if any of us betrayed him –]"

"I've had enough of this!" snapped Kayla's voice.

[Kayla barged into the room before we could react. Both of us turned, surprised, to focus on her, the sudden new danger]

[Kayla stood framed in the doorway, blocking the only way out. Stood tall and proud, like an avenging angel (?), carrying the rifle. I had trained her well/She remembered my training/even though she was angry, she remembered her training/; although she was obviously threatening Ethel with the gun, her finger was outside the trigger guard and the barrel was only pointed near her feet./Just as the other Marvin had told me, she had taken her training completely seriously; her brain had already loaded the rules I taught her as the unbreakable laws of firearms: <em>Never put your finger on the trigger until you're ready to shoot, and never point a gun at anything you're not willing to destroy.</em>]

[Long moment of silence, everyone staring at each other]

[Kayla broke the silence. "Eyewitness testimony is notoriously unreliable," she began [explaining things, as if she was delivering her proof; she could speak less-than-angrily because she had all the power in the situation]. "And part of that is because of <em>weapon focus</em>. If a witness sees someone with a weapon, they're more likely to pay attention to the weapon, and miss other details. But <em>you</em> barely glanced at my gun. You're looking directly at my face. Do you want to tell me why that is?"]

[I didn't understand, but Ethel had a look like she'd been caught]

"It's because you recognize me," Kayla went on [grimly]. "You want to see if I'm the same person you've seen on video, [in the recordings of dozens of experiments, which you stayed away from in order to keep your hands clean]"

[Dr. Wright lowered herself back into her chair, moving slowly/bearing her weight on spindly old arms, all of the energy-to-defend-herself drained out of her.]

["I… I cannot deny ????? I didn't want Fuller to do this,"]

["You didn't do anything about it"]

["but he was my only way/for sixty years I have defined myself by what I can do with my mind, do you understand what it's like for me to know how some mysterious adversary has been taking that away from me?"]

["How many other people's lives were you going to let be destroyed for that?"]

?????

She bowed her head. "Is this my judgment, then?"

"We are not God," I said, a bit reproachfully.

"Speak for yourself," said Kayla grimly, still poised to draw the rifle [the moment she chose]. But she knew she was in control of the situation. She had no intention of killing Ethel Wright in cold blood, but she wanted her to be afraid. She wanted her to ????? [experience the ????? that she had experienced? Understand how much her life was on the line, and Kayla was only reluctantly granting her mercy?] "<em>Unfortunately</em>, [we still need something from you, to protect us from something far worse than you are, so don't have the luxury to give you what you deserve. So you get to take the antidote. [Luckily for you, you're going to get exactly what you wanted. You get to know the truth. I hope it terrifies you]]"







[simon didn't show up early, so we decided to confront him in the meeting room. Physical description of the meeting room, with the giant table with screens built into it]

[Simon walked into the room without really paying attention to his surroundings, then suddenly noticed that things were different (Kayla with a gun), looked around nervously. Looking to the only person who (he thought) was someone he knew who might be in charge,] "Reggie, what's going on?"

"Take a seat," said Reginald gravely.

[The others interrogate Simon about the experimentation victims, but he plausibly claims he didn't know anything, not-entirely-convincingly claims that obviously he thinks it's horrible now that he knows about it "Obviously if that's what happened, I think that's horrible! But"; they angrily argue in circles a bit, not able to prove anything. Marvin interrupts:]

"You're the one who wrote the code for the time machine, right?"

"Uh, yeah?" [Simon looked back at me in a sort of wary way, unconsciously trying to figure out whether I was a threat or just Some Guy. I didn't usually get that look, so it was surprising, but he WAS basically being interrogated]

"We'll all forgive you if you just get in the time machine and go back in time by exactly 50 minutes."

Simon's eyes darted back and forth between the others. Reginald was protesting that he had never agreed to this, but Kayla had a quiet, intense look; she knew exactly what I was doing, and loved it. "Uh," Simon said to the group at large, "there's got to be a catch, right? There's no way something like that doesn't have a catch. Right?"

[I showed him on the screens built into the table, the code that said "<code>if dur > 50:</code>" and "<code>if dur < 50:</code>". Even after I pointed out it, he didn't realize what it meant at first. "What happens if the duration is exactly 50?" He thought about it a little, then gulped]

["Come on, I'm just a beginner, I was the only one 'in the know' who knew how to code, so I had to do all of it"]

["Of course it's okay for a beginner to make mistakes, but you KNEW you were a beginner, and you <em>chose to put your code into a machine responsible for people's life and death</em>! You're like the engineers responsible for the Therac-25!" I was already standing and roaring/it's so easy to get angry at other people for flaws that you've only just recognized in yourself (having worked for these people without asking too many questions)]

But of course, Simon didn't know about the Therac-25 either. So I explained it. This time, I didn't spare any of the details. I told him how ?????, how ?????, how ????? [don't actually describe it to the reader, just say that I told gruesome things to be characters]. [Simon had completely lost his cool [ability to act defensive], looked like he was going to throw up. Kayla and Reginald were looking on in horrified anger that this had happened]

Only Ethel Wright seemed unaffected by the details. But of course, she had been a physicist for sixty years. She had grown up in the aftermath of the bombings of Hiroshima and Nagasaki, and lived through the entire Cold War. The "demon core" incident, and every other nuclear criticality incident in history, had happened during her lifetime. Whenever [humanity discovered something new], they would use it to kill each other on purpose, to kill each other by accident, and to kill each other through negligence. This was not news to her.

?????

[I'm going to completely redesign the time machine, and you're going to help me. I'm going to do it using software best practices, unit testing, etc. I'm going to rewrite it in Rust!". The phrase "rewrite it in Rust" was a bit of a meme. Rust was another programming language, more modern, much better for writing reliable programs. Some people over-idealized it, like rewriting things in Rust would fix everything, but it was genuinely a better tool. Even if you used Rust, you still had to be careful, but Rust would <em>help</em> you be careful.]



[Ethics board in session – everyone is here]



[Also, is going back in time murder? Kayla says we SHOULD consider the idea that we are murdering and/or torturing billions of people by going back in time even once. So they have to talk about the basis of their moral system. Maybe Reginald says "when I said ethics, I did not necessarily mean we needed to go deep into moral philosophy"/"but of course we need to!"/" Yes, now that you say so, I can see that it was inevitable, given the unprecedented nature of the forces at play. I suppose we are not short of [he said the word with absolute disdain] <em>time</em> for such a discussion"… So what is the fundamental basis of morality?. Someone says that suffering is bad and satisfaction is good, and it's the total amount of suffering and satisfaction that makes the world good and bad. How do you tell whether to Something is murder? Well, the reason murder is bad is because it causes people to suffer]

"But then destroying the entire universe would be a morally neutral act" [because no one suffers afterwards]

A: "Yes. Destroying the entire universe is a morally neutral act."

[Something like [I feel like I've forgotten the proper way to state this though]: Moral statements generally arise from someone considering two possible ways things could go and decide that they like one of them better than the other, yes? But if you destroy the entire universe, there is no one who can make that comparison]

K: it's definitely not neutral. The goodness of the world is the total amount of satisfaction minus the total amount of suffering, across all sentient beings. Right now, there's more suffering than satisfaction in the world, so destroying the entire universe would be a good act. If we can make there be more satisfaction than suffering, then destroying the entire universe would be an evil act.

A: but there's no way to measure different people's satisfaction and suffering against each other; all we have are individual preferences, and if you destroy the universe, there are no longer any individual preferences to agree or disagree with


...so then the ends justify the means?

K: of course the ends justify the means. Every time people use it as an excuse for doing evil, they are not actually achieving good ends. In our bad society, people are always looking for excuses why it's okay to control or hurt others, and the excuses are always bad. 

[wait, this doesn't quite make sense? because it's pure hindsight bias:]

Simon? R?: if that's true then doesn't that make Doctor Fuller's research justified, to get us where we are now?

K: We could have done this much faster if it wasn't for all the evil! Aster said so

Reginald:[big declaration] Aster was wrong. [Explanation:] I have no doubt that Aster could have done better than Fuller given the same resources, but without Fuller's evil, we would never have had those resources in the first place. The whole team was formed by Fuller bullying people into it; without him, Aster would have been petitioning the committee and getting rejected. So Aster can only congratulate themselves for being better because they conveniently had an evil person to do the evil stuff for them. You have to sit with that. There are still people who excuse the Nazi human experimentation because we got scientific knowledge from it; we have to be able to say that it's always wrong.

Kayla: I DO say that it's always wrong! About the Nazi research, now we know how long it takes to freeze people to death, do you think it was worth it? Of course not! If it was actually worth it for the world, then you could convince people to consent to it, like they did in the Minnesota Starvation Experiment. Every single time people abuse other beings and make excuses for it: either it wasn't worth it, or they could have done it consensually

Reginald: not so impressed that you used the Minnesota starvation experiment as your example, that was draftees, so they were coerced. It's precisely the "conveniently there was someone else there to commit evil" that I am warning you about

Kayla: no I've thought about this, everyone in society is coerced and so you would have to say that no one can ever consent to anything, but obviously people can sometimes consent to things. The problem is if someone is stuck with abuse because it's the "least bad option", but this experiment wasn't like that: Starving is worse than working in a hospital or whatever, so we can trust that the subjects must have had reasons of their own will to take it. And you can confirm that by the fact that it's documented that none of them regretted doing it


[Hang on, hang on. Couldn't Aster still make loads of money with time travel?]





[Ethics of going back in time and repeating someone's suffering – does the suffering count twice, or once, or zero times? Ontoh says it only counts if it isn't reverted]

[Related, not sure of order: "this is basically the Star Trek transporter problem, right? If it destroys you and then re-creates you, is it really 'you'?" /How would you define that, philosophically?/Well, who's to say our entire universe isn't being destroyed and re-created at every instant? so if we use any definition that's broken by cut-and-paste, then we have no right to use that definition for anything even without time travel. I can only conclude that all your futures are equally "you". And/or: Ontoh says that it won't be the "surviving morality" because everyone who doesn't use time travel will inevitably die off, leading into:]

[maybe in response to that: it's a fascinating quirk of [Earth] culture that you think clipping a branch is the same as wiping out the tree./Seriously no one on Salnthu believes that?/I understand that there were some people who believed that in our ancient past, but everyone who believed that got wiped out./You persecuted them?/] "No, the belief caused them to die, of its own merits. [If you are never willing to reset any of yourselves, then eventually you'll die and not have any way to reverted]"

["What about souls? What about continuity of consciousness?" Those are superstitions. Let us ask why you believe in them; you believe in them because it simply feels like they are true, yes? Well, that feeling is something that exists; moreover, both copies have it.]

[Related, not sure of order: Ontoh says it's inevitable that the broadly accepted morality will be collective self-interest of those who can fight back ("just like how your society accepts breeding and slaughter of animals"); Kayla could relate collective self-interest to the Ring of Gyges story, but objects to the idea that morality is about the ability to fight back, and says [the powerful should do the right thing to the helpless]. Narrator remarks on this ("someone who was able to truly believe that you should do the right thing even if there would be no consequences… someone who had the [mental fortitude] to advocate for animals even in our society")]



[Somewhere: how should we think of Ontoh, who is essentially a slaveowner who grew up in a society of slaveowners? Ontoh believes it's the inevitable order of the world, and trying to stop slavery from happening is foolish (in Huvinthu it was only banned because of worries about rebellions). Marvin(?) agonizes about whether they're a product of their society; Kayla insists that they are Evil ("you can just look at what's happening and figure out what's good and evil! I can tell that my own society is evil [in the treatment of prisoners, children, animals, etc.], so they can tell that their society is evil, they just choose not to")]




[Ethics of reengineering the phrenochondria to make people stop abusing each other; ethics of removing them (removing them is nonconsensual mind control, but leaving them in is also nonconsensual mind control)]



[maybe somewhere while discussing the "morality of a god" thing – "then we are a necessary evil"

"Believing yourself to be a good person, and believing yourself to be an evil person, are both just ways of avoiding responsibility for your choices. [What's important is the process of looking for the best option available, and when you tell yourself a just-so story about what kind of a moral agent you are, you settle into a habit of not evaluating the options]"






[sometime with talking to Ontoh, not sure of ordering]

[K : this makes no sense, if you existed for septillions of subjective years, how are you not ahead of us in technology, haven't space travelled, etc.?

But it was already making sense to me. "'Work expands to fill the time available for its completion'," I quoted.

"What?"

"If you had a trillion dollars, you wouldn't care whether something cost one dollar or a thousand dollars, would you? You could spend a thousand dollars every second and still be a trillionaire. So in Salnthu, they had no reason to care whether something took one second or a thousand years, because they could make a thousand years ago by in an instant. Why make a faster computer when you can just]




[sometime with talking to Ontoh, not sure of ordering]

Ontoh: "What do you think happens if you bring a time machine back in time with you?"

[Uhhhh, do you destroy the fabric of space-time?]

Ethel had the answer to this one. [Her clear voice, immediately making sense of things and dispelling the fog] "[there's no way to physically distinguish whether you're in the interior of an argonian bubble./From the perspective of matter inside an argonian bubble, physics behaves the same as normal] So from the perspective of anyone who stays inside the bubble, it would have to behave exactly as you would expect for any other time machine. If you activated the inner time machine, you would 'go back' relative to <em>the time that the inner time machine experienced</em>, thus returning to what we'd call 'the future' from an outside perspective."



[Ethel: One develops an intuition for what observed behaviors might be emergent properties of physics, and what are based on human assumptions. And this budget rule doesn't feel elegant. [Are we in a simulation/imagined by a worldbrain? Was there another world before Salnthu, that somehow imposed the budget restriction?] I suppose it does have a certain stark elegance to it, in that you can never observe how much budget is left, because its only effect is to make your entire timeline cease to exist]


[Ethel: hmm, it could just as easily prevent the "duplicating objects" trick by having "pinched off" timelines count as a contradiction and reset. But that's physics for you, utterly arbitrary and indifferent to what humans think is intuitive]





[But how do we know Nochli are evil? They are just hanging around in the sky, we only have Ontoh's word for it that they are evil]

[As before, Kayla thinks their inaction makes them evil]

[Marvin's theory: What if they understood that their world was evil, and concluded that they would inevitably end up with a world like that as long as time travel was possible? So when they got the opportunity to replace their world, they decided to give humanity a new history, where they got to develop however they would have developed without time travel, and Nochli oversee it? Remember, Ontoh didn't understand how Nochli don't fight each other and how they agreed to remain in small numbers while overseeing the world. And Ontoh isn't trustworthy, they would probably just as happy to cancel our world to get back their own, so they have every reason to convince us that Nochli is evil]




[How the heck are we going to do anything against Nochli? Anything we do in this world will just get reverted. The time machines to get back to Salnthu are only big enough for written messages. MARTIN: well, let's see, they made resizable time machines before, right? What if we made a resizable time machine that was even more miniaturized, using Earth technology, and snuck it into their messages? The time machine could even contain us, like, secret agents, to infiltrate Salnthu. ONTOH: what are you planning to do? If you jump out on the other side, they will just revert you that way anyway; I have plenty of Ontohs in their base already, but that doesn't mean I can do anything about them. KAYLA [maybe with Ontoh feed turned off: Bomb Salnthu. "What?" No matter what we do, our entire world is going to be erased in a few months. At the very least, we shouldn't let Salnthu continue to exist either. Ontoh isn't going to consider options that also destroy Ontoh, but WE can. So let's combine time travel with Earth technology to make a bomb that can instantly wipe out all time machines, and all life, on the planet.]

[Come on, there has to be a way for Earth cultures to continue existing! [two Earths plan]]




[The stuff below probably goes in later chapters (after the duplications):]


[Wondering what to call the uninformed people]

["Muggles?" I suggested. "A Harry Potter reference? Really?" said Kayla irritably. Simon suggests "normies"; Marvin, whose irrationally peeved ("I knew it was petty, but") suggests "sheeple" as a joke. (Kayla's comment had gotten under my skin. I knew it was ?????. But I had grown up reading Harry Potter, and I was irrationally peeved; I wanted to make it look ridiculous. "How about <em>'sheeple'</em>, then?" I said [sarcastically?])]

Reginald's deep voice cut through our bickering. "<em>Civilians</em>," he said.

That was a sobering thought. [We were essentially [Earth]'s military now., And Reginald was reminding us to take our responsibility to Earth's people seriously]



[Reginald: God gives us difficult moral puzzles but it's our obligation to unravel them]

[Kayla: that's not true because God doesn't exist]

[Reginald: I'll thank you to not insult my beliefs]

[Kayla: I'm not insulting your beliefs, I'm telling you the truth. That's my whole thing, I see the truth when everyone else is able to deny it. In fact, why is this so hard for you to believe? We've just freed you from the mind control, and now you believe that time travel and Nochli exist. How come "God doesn't exist" is a bridge too far?]

[Surprisingly, Ontoh spoke up. "It is because he already knows that God doesn't exist."]

["What?"]

[Ontoh somewhat reserved tone, frowning-curious, not angry or judgmental (but remember the physical quality of their voice), "I was not intending to [discuss] these [Earth] superstitions, because it's not relevant to beating Nochli, but if it's going to become a conflict between [people on our team], we need to address it. His beliefs about time travel and Nochli are based on facts, so when he learned new facts, he changed his beliefs. But his belief in God is not based on facts, he believes it because he wants to believe it, so he wouldn't change it just because he learned new facts. But the real question is –"]

Reginald and Kayla both spoke at once.

"[That is an awfully reductive way to describe the practice of personal faith, but] –"

"People shouldn't go around believing things that aren't based on facts!" said Kayla angrily.

"But the real question is," continued Ontoh [calmly, unperturbed], "why do [the people of this timeline] <em>want</em> to believe in God?"

[We digested the implication. Next bit: Ontoh explains how monotheism originated with Zoroaster shortly after the introduction of the phrenochondria. People did believe in gods before, but they were adventurous legends about powerful people with human flaws fighting each other and such. The concept of a single all-powerful being, an ultimate authority, was completely new. People did not like being ruled over by kings and such; why would "being ruled over by the ultimate king" even be something that they would desire to fantasize about? Did Nochli intend this? It wasn't explicitly in the plan, but since the phrenochondria were intended, among other things, to make humans compliant, maybe it made them desire to have a ruler, and Zoroaster simply realized that he could take advantage of that desire. (Meanwhile: "what about Judaism, isn't that older?/Yes, but it wasn't monotheistic")]

[Potentially, somewhere during the above: Marvin unsettled by Ontoh's confidence "how can you be so certain that God doesn't exist?" Ontoh: "you do realize that your concept of God was invented during my lifetime? Maybe to someone who was born only tens of years ago, it could seem to be an eternal truth, but you can hardly expect me to believe in something that 'always existed' when the very concept of it didn't exist until quite recently."]


…and then I suppose Nochli would be happy to step into this role of 'God', when they reveal themselves





[maybe here, or maybe in part 3? "Salnthu never understood relativity or quantum mechanics. What's going to happen when we unite time travel theory with relativity or quantum mechanics? How do we know we're not going to discover a power that is even worse than Salnthu?"… philosophize about "wise enough to accomplish greater destruction" – if you cooperate effectively instead of fighting, then you accomplish greater deeds, and if you don't proactively guarantee that greedy people can't take your work and use it for evil, then they will, and your goodness will have accomplished the greater evil. Compare and contrast how Nochli, who was wiser than Ontoh, was able to destroy Ontoh, even though Ontoh was more focused on fighting]






