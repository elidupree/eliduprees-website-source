#!/usr/bin/python3
# -*- coding: utf-8 -*-




posts = [

{
"title": "Story idea: The Power of Love",
"tags": ["story ideas", "neurodiversity"],
"auto_paragraphs": True,
"blurb": "A certain individual gains The Power Of Love. Unfortunately, the only thing ze loves is to cause misery, so ze becomes a supervillain.",
"contents":'''
<p>(I've posted this elsewhere before, but I'm reposting it here because most of my blog audience probably hasn't seen it.)</p>

<p>(Content warning: discussion of abusive relationships.)</p>

A certain individual gains The Power Of Love. Unfortunately, the only thing ze loves is to cause misery, so ze becomes a supervillain. Ze makes people love each other so intensely that it throws their lives into ruin. Ze makes victims love their abusers, and ze makes stalkers love people who fear them. And if any of society's heroes or leaders use their power for good, ze makes them fall in love with someone who will exploit their powers for evil.

To oppose this villain, a new hero arises, who has The Power Of Friendship. Ze can project a magical force field called The Friend Zone. People in the Friend Zone automatically stop, think, and work out their problems with each other as if they are close friends. Our hero tracks down all the people who were influenced by the supervillain, and uses zir power to help them solve the problems the villain created. Despite their intense feelings, the power of friendship lets them pull through and make arrangements that are tolerable for everyone.

Anyway, ze's so successful at helping people that ze ends up with a crowd of admirers following zem everywhere, hoping ze'll friend zone them.

<h2>Discussion</h2>

I didn't <em>just</em> write this to make a joke out of the "friend zone" concept. (Don't worry if you don't know what that is &ndash; you're probably better off that way.)

On a more serious note, I think there's a problem with the idea of "true love". The feeling of love, like any other feeling &ndash; excitement, anger, pride &ndash; can either cause good things to happen, or it can cause bad things to happen, or both. So what is "true love"? Many people think that love only counts as "true love" if it's the good kind. So what should we call the bad kind or the mixed kind?

This isn't just a semantic dispute. Because love can hurt people, people NEED to have a way to talk about the kinds of love that can cause harm. Otherwise, how can they think about it without fighting with themselves? (<q>But it seems so much like love! But it's hurting me! But it seems like love, and love is good, right?! But...</q>) This applies to both the all-bad case (<q>he's only beating you because he loves you!</q>) and the mixed case, like where people have a loving relationship that is mostly good, but sometimes their love manifests itself as possessiveness that ends up hurting the other person.

If you're talking to someone, and they call this kind of thing "love", don't say "this is not love". Say the thing that matters: "this love is not good".
''',
},

{
"title": "Gods and atheism",
"tags": ["philosophical"],
"auto_paragraphs": True,
"blurb": "I'm not writing this post to convince anybody, but many people have found my beliefs about gods interesting.",
"contents":'''
I'm not writing this post to convince anybody, but many people have found my beliefs about gods <em>interesting</em>, so I figured I'd describe them here.

If someone asks, "are you an atheist?", I can comfortably say "yes", because I don't specifically believe in any gods. But if they ask "are you an atheist or an agnostic?", it gets more complicated. That's because the idea of a "god" can actually mean several <em>different</em> ideas, and I have different beliefs about each of them.

People often lump these ideas together, but they are quite distinct:

<h2>The Big Guy</h2>

This god goes around smiting people, performing miracles, making commandments, and so on. It's basically an immortal human with magic powers.

Most old religious books describe gods like the Big Guy. However, most religious people I've met don't really believe in a Big Guy &ndash; they believe in a different version of God. For instance, modern Christianity isn't really <cut>based on the descriptions in the Old Testament. Honestly, it shows up more as a talking point in bad atheist arguments (<q>Look! The idea of the Big Guy is silly! Therefore, ALL religious beliefs are silly!</q>).

I believe that <strong>we have sufficient evidence to conclude that no gods of this type exist</strong>. If they did exist, they would leave lots of evidence. Since we haven't seen that, we can conclude that they don't. This makes me a <a href="https://en.wikipedia.org/wiki/Strong_atheist">strong atheist</a> about this type of god. It's not <em>inherently</em> impossible for the Big Guy to exist, though. If somebody climbed out of the ground tomorrow and started striking things with lightning and turning shrubs into goats, I'd say, "yup, you could call that a god". I wouldn't necessarily <em>respect</em> it, though. Most of the gods from old religious books are tyrants and mass murderers.

<h2>The Designer</h2>

This god designed the world we know about. You could think of it as "the programmer of the cosmos". It designed the physics, then just left the world running for billions of years. Has it changed the world at all since then? Was it trying to create humans, or were they just an accident? Nobody knows.

It's impossible to find evidence against this god. No matter what you observe, the god could have just designed the world so that you would observe that. I suppose that makes me an <a href="https://en.wikipedia.org/wiki/Agnostic">agnostic</a> about this type of god. But my real beliefs are more like "This could technically exist, but I know it doesn't." That's probably how most people feel about <a href="https://en.wikipedia.org/wiki/Russell's_teapot">Russell's teapot</a>.

There <em>is</em> a difference between the teapot and the god. If the teapot exists, that doesn't explain anything. But if the Designer exists, that could explain the world we know about. But I don't want an explanation of <em>just</em> the world I know about. I'll eventually learn about something else (perhaps the Designer itself), and then I'll want an explanation of that too. Therefore, what I really want is an explanation of everything that exists. The-world-we-know-about can have a designer outside of the-world-we-know-about. But everything-that-exists <em>can't</em> have a designer outside of everything-that-exists, because if you're outside of everything-that-exists, that means you don't exist.

<h2>The Transcendent</h2>

This god is all around us. Do you feel it? It is love. It is the hum of the universe.

Specifically, this god <em>isn't</em> just an individual, intelligent person with great powers, like the Big Guy and the Designer are. So what <em>is</em> it, and does it exist?

To answer that, I'll ask a similar question: <strong>does the <em>sky</em> exist?</strong>

When we look upwards, we can say "there's the sky". The birds are in the sky. The clouds are in the sky. So when we say "the sky", do we mean "the atmosphere"? No, because we also say "the sun is in the sky" and "the stars are in the sky". Some of them are light-years away. Some of them have already exploded. If some of them are behind a hill, they are not "in the sky", even if they would be "in the sky" if you moved over by a few meters or waited an hour. It's clear that when we say "the sky", we're not talking about a specific thing that exists.

But <strong>here's the important part:</strong> if someone says, "the sky is beautiful this evening", not even the most picky atheist will say "you fool, don't you know the sky doesn't exist?". That's because the atheist understood what the person meant. Even though the person <em>said</em> "the sky", as if they were trying to refer to a thing that exists, what they <em>meant</em> was about their human experience of the sky, which <em>does</em> exist.

The Transcendent is similar. People have a lot of feelings, and they want to express them. Sometimes, "God" or "Divine" is the best word the people find to express them. That's not wrong.

Sometimes, when people talk to me about the Transcendent, they act as if <em>everyone</em> must have these feelings. This frustrates me, because I don't have those feelings myself. It's obvious to me that at least one of their beliefs is incorrect. But they don't necessarily have incorrect beliefs about <strong>gods</strong>. They might just have <a href="/blog/neurodiversity">incorrect beliefs about <strong>brains</strong></a>.

I'm not sure there's a term like "atheist" or "agnostic" for my perspective here. It has some things in common with <a href="https://en.wikipedia.org/wiki/Theological_noncognitivism">theological noncognitivism</a> &ndash; I think that descriptions of the Transcendent do not describe anything that <em>can</em> exist in a literal sense. But the difference is that my response is not, "ha ha, people who describe the Transcendent are thinking wrong!", but instead, "if they're not describing a literal existence, let me figure out what they <em>are</em> trying to express."
''',
},

{
"title": "Imagine a ball, but not what color it is.",
"tags": ["neurodiversity"],
"auto_paragraphs": True,
"blurb": "The first post in a series about my internal language.",
"contents":'''

<p>(I've been thinking about writing a blog post about my internal language. However, that might be a bit too complex for just <em>one</em> post. So this post might be the first in a series.)</p>

Can you imagine a ball, without imagining a ball of the specific color?

Can you imagine a handheld tool, like a hammer or a screwdriver, without imagining which one it is?

Can you imagine a person, without imagining someone of a specific gender or race?

For me, these things are not just <em>possible</em>, they are <em>automatic</em>. If you tell me "imagine a ball", I imagine the <em>idea</em> of ball-ness. Nothing else is specified. If you ask me, "what color is the ball you imagined?", that question doesn't make any sense. It's like if you asked me "what color is a crayon?". There are lots of different colors of crayons. I can't answer unless you ask something more specific.

For a lot of people, if you asked them to think of a ball, they would automatically think of a <em>specific</em> ball. They would have to do extra work to imagine the idea of a ball without imagining a specific ball. Or they might not even be able to do that. For me, it's the other way around &ndash; I actually have to do extra work to imagine a <em>specific</em> ball, but imagining a generic ball is trivial.

That's not my only trick, either. Watch this: I'm imagining one of the metal forks from my kitchen. And now I'm imagining that the fork still has <em>some number of pointy tines</em>, but not what specific <em>number</em> of tines it has. But here comes the good part: I'm separating the points from the tines. Now, on the right side of my mind, I have a metal fork with some number of tines, which don't end in any specific way. And on the left side of my mind, I have a row of points, which aren't made of a specific material, and aren't attached to anything.

What?

There's a couple of different things I need to explain <cut>here. Let's go!

<h2>Translation</h2>

Suppose you're thinking of an object, and you have to explain it to somebody else. To do that, you have to describe that object in words. I think of this as <em>translation</em>: you have to <em>translate</em> from thoughts to words. And then when the other person hears it, they have to translate your words into their own type of thoughts. If you're lucky, not too much information is lost in translation. But there's always <em>some</em> loss.

If you look at a real object and then think about it, that works a similar way. You <em>translate</em> the real object into thoughts. It's also possible to translate thoughts into a real object, although it's harder, because you have to actually create the object.

In all of these cases, some things can hardly be translated at all.

<ul>
<li>Words to thoughts: Try to translate "the if of about six tell" into meaningful thoughts, I dare you.</li>
<li>Thoughts to words: If you have a feeling, and you don't already know a word for that feeling, you usually can't translate it into words.</li>
<li>Objects to thoughts: If you see something completely unlike anything you understand, your thoughts won't be very good at describing what the thing is like.</li>
<li>Thoughts to objects: Most thoughts don't represent objects. The idea of friendship, for instance.</li>
</ul>

When I see a fork, I can translate it into thoughts. If I could shape metal, I could translate it back into an object, with pretty good accuracy. But I could also rearrange the thoughts into something that translates differently.

The individual words in "the if of about six tell" can normally have meaning, but I rearranged them into something that didn't mean anything. Similarly, I could take my idea of a fork, and rearrange it into a complete mess of curves, pointiness and metal. That's a form of mental gibberish, just like the English gibberish that I wrote earlier. By rearranging the ideas into a meaningless form, I deliberately made it impossible to translate into other forms. I can't make a real object that fits the "gibberish fork" description. I can't even write an English explanation that would let other people imagine the same "gibberish fork" that I'm imagining.

Do people usually have thoughts that are possible to translate into words? Or are most of their thoughts untranslatable? I suspect it's the latter. Most of my own thoughts don't have any obvious translation into English. The unusual thing about me is not that I <em>have</em> so many untranslatable thoughts &ndash; the unusual thing is that I <em>understand</em> my untranslatable thoughts well enough to say that.

It's fun to make up gibberish, just to see what it feels like. But there's lots of other interesting things to do, too. When I took the points off the fork, I created a new idea that <em>does</em> have some form of meaning &ndash; just an unusual one. And that brings us to...

<h2>Instantiation</h2>

Suppose I asked you to translate the phrase "a chair" into an object. In order to make a chair, you have to make a specific <em>type</em> of chair. Later, I can show your chair to someone else and ask them to translate it into English. But there will <em>never</em> be a guarantee that they translate it as "a chair". If you made the chair out of wood, for instance, they might translate it as "a wooden chair". By making the chair, you were forced to <em>add new information</em> that wasn't in the original phrase.

I call this <strong>instantiation</strong>. "Chair" is a <strong>category</strong>. A specific chair is a <strong>instance</strong> of that category. When you start with a category and choose an instance, you've <strong>instantiated</strong> the category. When you start with an object and choose a category that describes it, you've <strong>categorized</strong> the object.

Generally, instantiation adds information and categorization removes information. That's not completely true, though. Think about how someone could also translate the wooden chair as "a piece of wooden furniture". When you created the chair, you <em>added</em> the information of what kind of chair it was, but you <em>removed</em> another piece of information: the fact that the chair-ness was the important part. And there are many different layers of categories: "chair" is more specific than "furniture" is more specific than "tool" is more specific than "object".

<strong>All translation involves a lot of categorization and instantiation.</strong> Imagine that you're trying to explain the idea of "furniture", but in a language doesn't have a word for "furniture". You could do it by categorizing: "Big household objects that are used for holding your body or your possessions." Or you could do it by instantiating: "Things like chairs, tables, and beds." Usually, the best way is a combination of the two.

Compared with normal English, my own thoughts are much closer to the "category" end of the scale. When I translate from English to my own thoughts, I use a lot of categorization and only a little instantiation. So when I have to translate from my own thoughts back to English, I mostly have to instantiate them. It's <em>possible</em> to write in English at my normal level of categorization, but not generally a good idea. Imagine if I had written this post like this:

<blockquote>
Can you imagine an object of some specific type, without imagining the object having any attributes other than being an object of that type?

For me, that's not just <em>possible</em>, it's <em>automatic</em>. If you tell me to imagine an object, I imagine the <em>idea</em> of that type of object. Nothing else is specified. If you ask me about a specific attribute of the object I imagined, that question doesn't make any sense.
</blockquote>

That looks worse even to me. English just isn't suitable for this kind of thing. In English, it's much better to explain things by example.

Back to the fork example: When I took the points off the fork, that was something like categorization. I started with a fully detailed fork, and separated out just the <em>idea</em> of a row of points. You could call this a "phrase" in my internal language. It translates pretty well to English: "row of points".

But now I can break it down more. I can separate the row of points into just the <em>idea</em> of pointiness, and the <em>idea</em> of a row of something. And those two ideas can't be broken down further. So you could say they are two  of the the <strong>words</strong> of my internal language.

In <a href="/blog/what-my-internal-language-is-made-of">the next post in this series</a>, I'll talk about what my words are made of, and how I define them.

''',
},


{
"title": "“Tuning out” and “Dream thinking”",
"tags": ["neurodiversity"],
"auto_paragraphs": True,
"blurb": "These are a couple of my mental techniques for problem-solving.",
"contents":'''
These are a couple of my mental techniques for problem-solving.

<h2>Tuning out</h2>

Sometimes, I work on the same problem for a long time, but I get stuck. I keep thinking of slightly different solutions, but none of them actually work. Focusing really hard on the specific problem isn't helping me. So I "tune out". I keep directing my brain to think about the problem, but I relax and don't focus so hard on specific solutions. Doing this often gives me useful new ideas.

I'm going to try to explain exactly what I'm doing and how it helps. But before I can do that, I have to explain some things about how brains work.

Let's say someone shows me a picture of a bear. I can immediately say, "that's a bear", without having to think about it. How did I do this?

<p><em>Somewhere</em> in my brain, there's the knowledge of what a bear is. But there's also a lot of other knowledge. Suppose my brain had a single CPU, and it had to go to all the knowledge one at a time. "Is it a twig? Nope. Is it a sack of potatoes? Nope. Is it the Burj Khalifa? Nope. Is it..." This process will eventually get to "Is it a bear?", but it will take forever. So that can't be how it works.</p>

Instead, I want you to imagine that my brain has separate processors for every single <cut>piece of knowledge. When I see the picture, all of the processors start analyzing the picture at the same time. The "twig" processor sees that it's not a twig and shuts up. The same thing happens with most of the others. But the "bear" processor sees that it <em>is</em> a bear, and starts yelling, "It's a bear! It's a bear!". Now, the rest of my brain also knows that it's a bear. And that includes the brain-part that allows me to speak the words "it's a bear" out loud.

Now let's say you ask me something else about the picture, like "How tall you think this bear is?". Now, I don't want to keep thinking about the fact that it's a bear. I want to think about the specific details instead. I need a way to get the "bear" processor to stop yelling "bear, bear, bear". So I make an announcement to <em>all</em> the processors: "Only send me information related the height and proportions."

This is a <strong>context change</strong>. This almost always happens automatically. Most people don't even think about the fact that they're doing it.

Your context can also be <strong>sharper</strong> or <strong>less sharp</strong>. Some people can focus very sharply on a specific subject, and suppress almost all other information. There are stories about researchers not even noticing what's going on around them, because they are working on a problem so hard. I'm not quite as extreme, but I do think I'm above average in how sharply I focus on things.

A sharp focus has an advantage &ndash; you won't be distracted by useless information. But it also has a disadvantage &ndash; some of the information you suppress might actually be useful.

That's where "tuning out" comes in. When I'm trying to solve the problem, I normally focus as sharply as I can. When I "tune out", what I'm really doing is <em>making my focus less sharp</em>. That way, I can receive more information that might be useful.

There are other things I can do, too. Because I've practiced this a lot, I have a lot of conscious control over exactly what context I'm using.

Sometimes, I alternate between tuning out (to get more information) and tuning back in (to analyze the new information in more detail).

Other times, I change the context in other ways. For instance, I might say to myself, "Okay everybody, I have this task I need to do lots of times in a row, so give me any information about doing this kind of thing <em>quickly</em>. Don't worry if it solves the problem exactly." (I don't actually say those <em>words</em> to myself &ndash; it's something I understand internally. This is just my best translation of it.) Once I get that information, I might be able to rearrange my original problem so that it can use the quicker solution. Or even if the quicker idea doesn't quite work, it might inspire me to think of something that does.

<h2>Dream thinking</h2>

There are a bunch of stories about scientists having brilliant ideas in their dreams. That hasn't happened for me, but I <em>do</em> often have good ideas while I'm going to sleep or waking up in the morning.

One time a couple years ago, I got out of bed, but didn't really feel completely awake. My thoughts were still sort of random and incoherent, the same way they are in my dreams. Instead of trying to wake myself up, I started thinking about a programming problem I had been working on the previous day. I actually came up with a lot of good ideas that way.

That got me thinking: Can I make myself have dreamlike thoughts on purpose? So I experimented with trying to make my thoughts less dreamlike and then more dreamlike. I actually got pretty good at it. I don't think I would have been able to figure this out if I had been fully awake in the first place. But now that I have figured it out, I can take my thoughts about halfway to the dreamlike state even when I'm fully awake.

"Dream thinking" is like a more extreme version of tuning out. When I use dream thoughts, I don't <em>just</em> turn off the context. I also turn off another thing: the part of my brain that tries to make everything makes sense. I just let my brain keep running with whatever ideas it comes up with, even if those ideas don't initially seem to make sense or relate to the problem. You could put it this way: "If you've already tried all of your ideas that make sense, and they didn't solve the problem, try some of the ones that don't make any sense."

Dream thinking is a lot harder to control than tuning out. The dream thoughts tend to run off and think about things completely unrelated to the problem. When I tune out, I still stay in the same context &ndash; just not as sharply. But dream thinking gets a lot less effective if I try to restrict the context <em>at all</em>. Instead of trying to <em>stop</em> those thoughts, I just keep running different parts of the problem through my head and letting the thoughts go wherever they want with them.

This tends to give me a lot of useless and/or <a href="/blog/imagine-a-ball-but-not-what-color-it-is">untranslatable</a> ideas. But it's great for finding ways to look at the problem from a new perspective. I come up with a lot of things that I would never have thought of if I just discarded everything that doesn't make sense at first.



''',
},

{
"title": "How to Train Your Brain, Part 1",
"tags": ["neurodiversity"],
"auto_paragraphs": True,
"blurb": "Since other people haven't invented the best techniques yet, I was forced to invent a lot of techniques myself.",
"contents":'''

A lot of people assume that you can't train creativity or intelligence. I know that's not true, because I've done it myself. That is, I have improved my intelligence &ndash; including <a href="https://en.wikipedia.org/wiki/Fluid_intelligence">fluid intelligence</a> &ndash; through deliberate training.

Here's the real reason people think you can't do it: We just haven't figured out the best <em>techniques</em> for training your brain yet. That's understandable, since brains are complicated and <a href="/blog/neurodiversity">different for different people</a>. Since other people haven't invented the best techniques yet, I was forced to invent a lot of techniques myself.

I'm very interested to see whether I can share my techniques with other people. A lot of them are internal and <a href="/blog/imagine-a-ball-but-not-what-color-it-is">untranslatable</a>, but I think a lot of them can be explained &ndash; and they might even be useful for other people. This post is my first attempt to do that.

<h2>The basics</h2>

I'm going to explain a few of the basic ideas that I always use when I train myself. This is <strong>general brain training</strong>. It's not specifically "intelligence training" or "anger management training" or "memory training", although I've used it for all of those things.

To help explain the ideas, I'm going to use a specific example from my life. When I was around 10 years old, <cut>I was a bit nervous about going into dark places. I thought that was a silly thing to be nervous about, so I changed it, using an older version of these techniques. I'm going to use this example because it is a relatively <em>simple</em> task: "I get nervous, and my goal is to stop getting nervous." Intelligence is much more complicated, so I'm going to leave that for a later post.

<h3>1. Observe your brain</h3>

"I get nervous when I go into dark places" is a good place to start, but there's lots more to learn. Am I nervous about the <em>idea</em> of going into the dark, or only the actual <em>experience</em> of having the darkness around me? If I <em>imagine</em> going into a dark place, does that trigger the nervousness too? What if I imagine different <em>kinds</em> of dark places &ndash; big open ones, small cramped ones, etc.? How about turning all the lights off in a room that I'm already standing in?

When you're doing this kind of thing, the goal is to imagine something that will <em>trigger the nervousness on purpose</em>. The more different ways you find to trigger it, the more you'll understand where it's coming from. You could think of yourself like a doctor, poking in different places to see where it hurts.

By exploring these questions, you can figure out exactly what part of your brain is causing the problem. In my case, it turned out that my brain was perceiving unknown dark spaces as a <em>possible threat</em>. I was nervous about going <em>close</em> to a large dark space, but I wasn't bothered by darkness if I already had a good sense of what was around me. For instance, a tiny dark closet wasn't a problem at all, because my brain didn't feel like there was enough room in the closet for anything spooky.

If you're trying to gain a new ability instead, look around your brain for anything that does something similar to what you want. Just like before, keep poking it in different ways to see what makes it do its thing.

<h3>2. Teach it the correct way</h3>

Once I knew what I wanted, I repeatedly imagined myself going into dark spaces <em>while remaining calm</em>.

Your conscious thoughts are only a tiny part of your whole brain. Your conscious thoughts are easy to change, but that's not the point &ndash; the point is to change the large mass <em>behind</em> the conscious thoughts. You could imagine your conscious thoughts as a broom, and the rest as a huge heap of sand. Dragging the broom a long way away won't move the sand, but if you move the broom in just the <em>right</em> way, you can slowly <em>sweep</em> the sand in the direction you want.

So how do you sweep your brain? Generally, when you imagine doing something, it uses a lot of the same neurons that you use when you <em>actually</em> do the thing. By imagining something, you can walk yourself through the process that you <em>want</em> to happen, rather than the process that happens normally. Think of it as waking up a specific part of your brain, then showing it what to do.

This is where your observations become really important. You have to wake up the exact part of your brain that you want to change. In my case, I had to imagine exactly the situations that would normally make me nervous. I could have easily imagined staying calm while going in a dark closet, but that wouldn't have been useful.

<h3>3. Never fight with yourself</h3>

If you're trying to imagine staying calm, and you find yourself feeling nervous anyway, <em>don't</em> keep trying to stay calm. Stop imagining and start over, and try doing it a different way next time. Your brain will remember exactly how you imagined it, whether it was right or wrong. You can never teach your brain that the <em>wrong</em> way is <em>wrong</em>. You can only teach it that the <em>right</em> way is <em>right</em>. 

Therefore, you have to keep thinking of new things to try until you find one that works <em>and</em> is right. Maybe you can make it work if you practice imagining similar things, then come back to the important one after you've gotten more automatic at imagining it the right way. Maybe instead of trying to replace nervousness with calm, you can focus on a stronger feeling, like pride or conviction.

A lot of people talk about "suppressing" their emotions, or keeping them "bottled up". This is completely different from my techniques. When you suppress an emotion, you're not changing that part of your brain at all &ndash; you're just trying to stop it from waking up. With my techniques, you deliberately wake up the problem parts, so that you can permanently reshape them to be less of a problem.

In Part 2, I think I'll talk about how I use these same techniques to make myself better at remembering new information.


''',
},

{
"title": "How to Train Your Brain, Part 2: Memory",
"tags": ["neurodiversity"],
"auto_paragraphs": True,
"blurb": "How to apply my techniques to learning and memory.",
"contents":'''
This is the second post in a series. You should <a href="/blog/how-to-train-your-brain-part-1">go read Part 1 first</a> if you haven't.

This post is about how to apply the same techniques to <em>learning and memory</em>.

<h2>A simple example</h2>

This post <em>isn't</em> just about rote memorization, but talking about rote memorization will help to introduce some ideas. Let's say I'm trying to memorize this quote:

<blockquote>If there is no struggle there is no progress. Those who profess to favor freedom, and yet depreciate agitation, are men who want crops without plowing up the ground. They want rain without thunder and lightning. They want the ocean without the awful roar of its many waters. This struggle may be a moral one; or it may be a physical one; or it may be both moral and physical; but it must be a struggle. Power concedes nothing without demand. It never did and it never will.
<br><br>
&ndash; Frederick Douglass<footnote((Alas, this quote is still relevant more than 150 years later. I want to say "I'll prove you wrong, Frederick Douglass! I'll seize power and then concede something without demand. That'll show you!" But what Douglass is really saying is that violent resistance can be justified as a way to end injustices, which is something I actually agree with.))></blockquote>

First, I'd read the quote a few times on the page. Then I'd look away and try to repeat parts of it from memory. I'd go back and forth until I could repeat the whole thing.

The obvious way is to memorize the first line, then the first two lines, then the first three lines, and so forth. But some people suggest that you first memorize the <em>last</em> line, then the <em>last</em> two lines, and so forth. This can be a good technique. Explaining <em>why</em> it's good will be a bit more complicated:

I want you to imagine memory as a <strong>set of one-way arrows</strong>.

<ul>
<li><q>If there is no struggle there is no progress.</q> &#8594; <q>Those who profess to favor freedom,</q></li>
<li><q>Those who profess to favor freedom,</q> &#8594; <q>and yet depreciate agitation,</q></li>
<li><q>and yet depreciate agitation,</q> &#8594; <q>are men who want crops without plowing up the ground.</q></li>
<li>...etc.</li>
</ul>

<p>(It should be obvious that the arrows are one-way: you can't repeat a quote backwards just because you can repeat it forwards!)</p>

In order to memorize the quote, you have to <strong>build</strong> each of these arrows in your mind. That's what happens automatically when you memorize something. But there are ways to make the process easier or harder.

When you try to look away from the page and repeat first two parts, you're <em>trying</em> to build this:

<ul>
<li><q>If there is no struggle there is no progress.</q> &#8594; <q>Those who profess to favor freedom,</q></li>
</ul>

But what if you forget the second part before you get to it? Then you end up with:

<ul>
<li><q>If there is no struggle there is no progress.</q> &#8594; "Uhh... what was the next part?"</li>
</ul>

<em>This actually gets recorded as a memory</em>. Remember from Part 1: Your brain will remember exactly how you imagined it, whether it was right or wrong. Later, your brain will sometimes automatically follow the "&#8594; I forget" path, unless the "&#8594; [actual next line]" path is much stronger. In order to memorize things well, you need to make sure that you <em>will</em> still remember the second part when you get to the point where you can record it.

That's why starting from the end can be useful. If you've memorized the first four lines, and you are trying to add the fifth, then you have to remember the fifth line while you repeat the first four to yourself. But if you've memorized the <em>last</em> four lines, you can <em>start</em> with the fifth-to-last, and then proceed into ones you already remember pretty well.

But that's enough about rote memorization. Let's get into the good stuff:

<h2>A more sophisticated example</h2>

Let's say I'm trying to learn all about how trees work. At some point, I learn that they bring water from their roots up to their branches using <a href="https://en.wikipedia.org/wiki/Capillary_action">capillary action</a>. I obviously want to form these memories:

<ul>
<li>Capillary action &#8594; trees use it to lift water</li>
<li>How trees lift water &#8594; capillary action</li>
</ul>

Remember, memories are one-way, so these are two <em>separate</em> memories, even if you usually form them at the same time. So when I'm really trying to remember something, I often go over it in my head both ways. Capillary action, trees; trees, capillary action.

Also, what I really want to happen is to remember this a while in the future, when I <em>haven't</em> just been studying it. Recall from Part 1 that you have to wake up the exact part of your brain that you want to change. I want to be able to remember this even <em>without</em> all the other context. So I specifically <em>try to clear my brain of all the other context</em>. I imagine that I've just run into the term "capillary action" and want to remember some things about it, sometime when I <em>haven't</em> just been thinking about trees. <em>Then</em> I lead my brain through the other related knowledge.

And that's not even the good part. If I build the two memories above, it's like using my brain as a dictionary. A dictionary contains lots of information, but it doesn't know how to <em>understand</em> or <em>interpret</em> that information. My goal isn't to learn <em>facts</em> about trees &ndash; my goal is to understand the <em>system</em> of trees.

Therefore, when I learn a new fact, I specifically try to build a lot of memories related to understanding the systems behind it. I play around with the fact in my mind, trying to relate it to other things I know. In this case, I might build memories like these:

<ul>
<li>Things that happen in tree roots &#8594; collecting water for capillary action</li>
<li>Things that happen in tree leaves &#8594; pulling water through capillary action</li>
<li>Ways various lifeforms transport water &#8594; capillary action</li>
<li>Ways plants exploit quirks of physics &#8594; capillary action</li>
<li>Things trees need in order to survive &#8594; moving water from roots to branches through capillary action</li>

</ul>

And when I think of each memory I want to build, I do the "imagining it without context" thing again. I imagine that I have only been asked "what are some things that tree roots do?", when I wasn't thinking about the other stuff. And so on for each of the others.

<p>(I don't worry about trying to build the reverse memories for these ones. That tends to happen automatically when I'm trying to think of what memories to build. And besides, if I was able to come up with those ideas just now, I can probably come up with them again in the future.)</p>

Forming these the extra memories helps me understand things faster and better. You start with a <em>list</em> of facts. This technique transforms it into a <em>network</em> of facts. That way, you can remember each fact <em>whenever it might be helpful</em>, rather than just when someone asks about that fact specifically.

''',
},

{
"title": "Why should knowledge be correct, anyway?",
"tags": ["philosophical"],
"auto_paragraphs": True,
"blurb": "A fable about how we come to understand things.",
"contents":'''
Let me tell you a fable about how we come to understand things:

One time, long before geometry was invented, Uzoma and Carmen were standing at the corner of a square racetrack.

"I wonder what shape this racetrack is," said Carmen.

"Well," said Uzoma, "I have run along it many times, and I always get back to where I started. So it must be a circle."

"You fool!" exclaimed Carmen. "It has a corner right here! Circles do not have corners!"

"I guess that's strange, but I still think it's a circle," said Uzoma.

"Hmph," said Carmen. "You're being unscientific. None of our theories fits the evidence, so we can only conclude that we do not know what shape it is."

A few months later, the rainy season came. There was a lot of flooding. Uzoma and Carmen built a wall to block the flood, but <cut>the water just poured around the ends of the wall. They build a bigger wall, but the same problem happened. Very frustrated, they tried to figure out how to solve this problem.

"I have an idea," said Uzoma finally. "A <em>circle</em> separates the inside from the outside. So if we build the wall along the racetrack, which is a circle, it will keep the water out."

"It's not a circle," said Carmen. But Carmen didn't have any better ideas, so the two of them built the wall along the racetrack. They were safe from the floods after that.

<em>Uzoma or Carmen &ndash; which one had better knowledge?</em>

<h2>Discussion</h2>

Uzoma's knowledge wasn't <em>correct</em>, but it was <em>useful for finding other correct knowledge</em>. When Carmen threw away the incorrect knowledge "the racetrack is a circle", ze also threw away the chance to discover the correct knowledge of how to protect from the floods.

I always want to find the truth. But finding the truth has two parts. In the first part, you imagine any wild idea you can think of that could help you understand. In the second part, you doubt your ideas, trying to figure out which of them are actually good. Eventually, you alternate between the two parts, developing and refining your ideas until you're satisfied.

It's not wrong to doubt &ndash; in fact, it's very important. Carmen simply doubted <em>too early in the process</em>. As long as Carmen throws away every idea that isn't completely correct, ze won't learn anything until Uzoma gets all the way to inventing the <a href="https://en.wikipedia.org/wiki/Jordan_curve_theorem">Jordan curve theorem</a>. In the early parts of the process, we shouldn't judge ideas based on strict correctness. We should judge them based on whether they are <em>useful for understanding</em>.

When I describe memory as <a href="/blog/tuning-out-and-dream-thinking">a bunch of parallel processors</a> or <a href="/blog/how-to-train-your-brain-part-2-memory">one-way arrows</a>, that's what I'm doing. I don't believe those things because I can prove they are exactly correct &ndash; in fact, they're probably not. I believe them because believing them has given me the power to understand and accomplish things.

This issue can come up in a lot of different scenarios:

<ul>
<li>When I learn a new (programming) language, I imagine that it works mostly like languages that I already know. After I make a lot of guesses, I eventually learn where I'm wrong. This is much faster than trying to study the grammar from the ground up.</li>
<li>I'm a white person. When a person of color tells me how racism works, I shouldn't doubt it just because their theory is incomplete. Theories of racism can never be truly completed because racist institutions keep evolving, so we have to use the best theories we can get at the time.</li>
<li>I have developed a lot of beliefs about how to write well. Because <a href="/blog/in-which-i-rant-about-the-study-of-english">the idea of "good writing" is inherently subjective</a>, these beliefs inherently can't be "correct". But they've enabled me to write things that a lot of people like, so they are clearly useful for something.<footnote((One might ask, "can these really count as beliefs, if you don't think they're correct?". Well, you could say that I still believe they are true <em>within some context</em> &ndash; I just don't know exactly where the boundaries of that context are. And I'm not <em>completely</em> certain about any specific belief, but it would be silly to say that I don't have any beliefs. Perhaps it makes more sense to view the mind as an ecosystem of contradictory beliefs, rather than a logic machine.))></li>
</ul>

Western science training focuses almost entirely on finding the best ways to doubt. This is a useful skill. But we also need to learn the best ways to <em>imagine</em>, and our training for <em>that</em> is far less well-developed.


''',
},

{
"title": "Supervillains are cool",
"tags": ["writing","story ideas"],
"auto_paragraphs": True,
"blurb": "Tell me, why is this character the villain?",
"contents":'''
Supervillains are cool.

Don't get me wrong. The story of a superhero is a story of empowerment. The reader &ndash; an ordinary person who can't easily fix the problems in zir society &ndash; gets to imagine having awesome powers and saving the world.

But if the superhero is empowered, the supervillain is even more empowered. Ze doesn't just have more <em>physical</em> power (although that's still true, so that the audience can root for the underdog). Ze also has more <em>freedom</em>. Ze isn't limited by laws or social norms. Ze can do anything ze wants to. The supervillain, and ze alone, has a vision to change the world.

Tell me &ndash; why is this character the villain? Many of our laws are unjust. Many of our social norms are repressive. In a typical story, the hero stops the villain's plan and restores the status quo. But in our world, the status quo is not good, and has never been good. To reach a good world, we <em>need</em> a vision for a change.

Give me a story where the hero accepts everyone's identity and sympathizes with everyone's struggles, not because the wise old mentor told zem to, but because <em>fuck the rules</em>. Give me a story where the hero ignores people's hypocritical moralizing, not to become evil, but to forge a better morality. Give me a story where the hero has a genuine project to change the world.

And then let the hero succeed.

''',
},

{
"title": "How to make your fantasy setting less racist",
"tags": ["writing"],
"auto_paragraphs": True,
"blurb": "Suppose I'm a white supremacist, and I want to write a fantasy story. What kind of story do I write?",
"contents":'''
Suppose I'm a white supremacist, and I want to write a fantasy story. What kind of story do I write? Maybe it would be something like this:

<ul>
<li>There is a "white" race, which is consistently portrayed as normal or good. Other races are usually portrayed as unusual, exotic, and/or bad.</li>
<li>Races are clearly separated from each other. Interracial relationships are rare or nonexistent. There is no significant population of mixed-race people.</li>
<li>The white race may have some variety, but non-white races are often one-dimensional caricatures. The question "why are they attacking people?" doesn't need much of a reason beyond "they are [race]".</li>
<li>However, I want to spread my propaganda without everyone instantly knowing how racist it is. So, I don't explicitly label the races "white", "black", etc.. Instead, I make them fantasy races that just have some <em>superficial traits</em> of the human races I'm thinking of. The audience can figure out what I'm implying for themselves.</li>
</ul>

What have I just described? This isn't just some weird thing done by a few white supremacists. It's a staple of modern fantasy. It's <em>Humans and Orcs.</em> In a lot of modern fantasy, all humans are white, and <a href="https://chroniclesofharriet.com/2012/01/19/racism-role-playing/">orcs are people's worst stereotypes about black people</a> (and/or other <a href="https://en.wikipedia.org/wiki/People_of_color">PoC</a>), just with the name changed.<footnote((Note that <em>Tolkien's</em> fiction, which is the original source of orcs, is not quite like this. Tolkien's fiction features good dark-skinned humans, such as Ghân-buri-Ghân, and many mixed-race people, technically including all hobbits. Tolkien's writing is not free from racism, but its racism is very different than the things that have come after it.))>

I'm going to single out <cut>two video games here: Hearthstone and Battle for Wesnoth. I'm focusing on these games because I enjoy playing them online. Thus, in a way, my actions help to <em>promote</em> these games. I feel like I have a duty not to promote racist things without at least criticizing them as well.

In both games, all humans are white.<footnote((Wesnoth has recently introduced the "Khalifate", a group of humans who clearly represent Arab Muslims. However, their race isn't even listed as "Human", but instead as "Khalifate Human", as if Muslims can't just be regular-human like the rest of us. Also, it's strange to include a "Khalifate" in a fantasy game that generally avoids real-life religious terms. Imagine how you would feel if you played a game where the races were Humans, Elves, Orcs, and Christians.))> Hearthstone has plenty of green people and some blue and orange people, but no brown people. Wesnoth does it one worse by making the brutish orcs literally have brown skin.

Humans have Knights, Crusaders, Kings, and Priests. Orcs have Warriors, Warlords, Chiefs, and Shamans. In real life, I ask you, what races of people are normally called each of these things? That should tell you what kind of thoughts about race the authors were having when they created these settings.

Hearthstone also misuses terms from various cultures just to add flavor to the game. It has "Totems" and a "Voodoo Doctor", although I'm certain no Ojibwe people or Voodoo practitioners<footnote((Of <em>either</em> of the religious traditions often called "Voodoo".))> were consulted during the making of the game. These things are associated with orcs and trolls, adding to the "human = white" implications.<footnote((Both games also have <em>elves</em>, which are an interesting complication. In Wesnoth, elves are just as white as humans. Even the desert elves from <em>Under the Burning Suns</em> have the same skin tone, even though they should logically have much more melanin, if only from tanning. In Hearthstone, they have different skin tones (such as purple), but still use cultural terms/ideas associated with white people. Elves tend to vary between different fantasy settings. In some, they aren't quite white. In others, they are super white.))> Humans are also much more likely to speak in Standard English, while trolls often borrow grammar from <a href="https://en.wikipedia.org/wiki/AAVE">AAVE</a>.

Naturally, none of these things are unique to Hearthstone. They are common to many modern fantasy settings. And it seems likely that most of them are unintentional. If a writer is trying to include some spooky magic, they may reach for the term "voodoo", without thinking about the actual religious tradition. If they are trying to write dialogue for a stupid character, they may reach for grammar from AAVE simply because they've seen the same grammar on stupid characters in other stories. They don't realize that this originated from deliberate attempts to portray black Americans as stupid. But because they don't know, they end up repeating the same harmful implications.



So what do we do about all this? There are many possibilities.
<h2>1. Don't use fantasy races.</h2>

Probably, we should create new fantasy stories, which don't rely on the cliché of human-like races with distinctive traits. But even within this kind of fantasy setting, there are lots of other things you could do to avoid some of the problems.

<h2>2. Make all the humans black.</h2>

Well, why not?

Sure, some assholes will call you an <a href="https://en.wikipedia.org/wiki/Social_justice_warrior">SJW</a> who drags race into everything. But if making all humans black is dragging race into it, then making all the humans <em>white</em> is dragging race into it just as much. The only difference is that all-white humans are so common that they don't even stand out. But if it's so common for people to write stories with these kinds of white-supremacist undertones, that's all the more reason for us to write stories with a different message.

You could also make humans be a broad assortment of real-life races (which might or might not happen to have any white people in it).

You could even use the cliché fantasy story where the Evil Hordes invade the Good Kingdom just because they can. This isn't even an unrealistic story. The only unrealistic thing is PoC doing it to white people instead of the other way around. You could have your Orcs be a fantasy-ized version of white European conquerors.

<h2>3. Get rid of the <em>humans</em>.</h2>

Fantasy races can be an interesting way to explore the different sides of real-life humanity. Say, you can have the passionate people, who are made out of fire, and the intellectual people, who are made out of air. If one of the races is actually called "humans", that messes up the metaphor.

The important thing here is for the fantasy-racial divisions <em>not</em> to represent real-life racial divisions. However, this is actually quite difficult. Almost all terms for social roles have racial connotations in one way or another. One possible technique is to invent your own terms for the roles in your fictional cultures. This is fairly common in fantasy novels, but can't be used all the time without making things harder for the reader.

A more thorough thing to do is to make detailed designs for all of your fictional dialects and cultures. If you find a specific reason for each cultural quirk &ndash; a reason that arises from your own fiction &ndash; then it's easier to avoid falling into stereotypes. Even this isn't foolproof, because your own assumptions about race may be built into the foundation. However, it can catch some of the more careless stereotypes.

Ultimately, your story's portrayal of racial issues can only be good as <em>your</em> understanding of racial issues. If you've grown up in a racist society, it can be hard work to keep racist implications out of your own stories. The important thing is to do that work while you're writing, instead of trying to justify yourself afterwards.




''',
},

]

"""

{
"title": "On evil people
"tags": ["philosophical"],
"auto_paragraphs": True,
"don't deploy": True,
"blurb": "",
"contents":'''
I don't really believe in the idea of "evil people". Everyone does some good actions and some evil actions. If we want to make the world a better place, we should take the people we have and figure out how to make their actions better, not try to pick out which people are evil.

But for this post, I'm going to imagine that the idea of evil people is a useful, and see where it leads me.

Specifically, let's assume:

<ul> <li>
''',
},



#A template for new posts, which I copy each time I start one.
{
"title": "
"tags": [],
"auto_paragraphs": True,
"don't deploy": True,
"blurb": "",
"contents":'''

''',
},

"""
